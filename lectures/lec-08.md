# Лекція 08 Побудова CI конвеєрів у сучасних платформах

## Вступ

Безперервна інтеграція є фундаментальною практикою сучасної розробки програмного забезпечення, що дозволяє командам регулярно інтегрувати код у спільне сховище з автоматичною перевіркою якості. Розуміння принципів побудови CI конвеєрів та особливостей різних платформ є критично важливим для створення ефективних процесів розробки.

## Концепція безперервної інтеграції

Безперервна інтеграція виникла як відповідь на проблеми традиційної розробки, де інтеграція коду відбувалася рідко і призводила до складних конфліктів. Мартін Фаулер визначив безперервну інтеграцію як практику розробки, при якій члени команди інтегрують свою роботу часто, зазвичай кожна людина інтегрує принаймні щодня, що призводить до декількох інтеграцій на день. Кожна інтеграція перевіряється автоматизованою збіркою для виявлення помилок якомога швидше.

Основна ідея полягає у зміщенні виявлення проблем ліворуч у часовій шкалі розробки. Чим раніше виявлена проблема, тим дешевше її виправити. Якщо помилка знайдена через кілька хвилин після написання коду, розробник ще пам'ятає контекст і може швидко її виправити. Якщо ж помилка виявляється через тижні або місяці, час на її локалізацію та виправлення зростає експоненційно.

Класична безперервна інтеграція базується на кількох ключових принципах. Перший принцип полягає у підтримці єдиного джерела правди у вигляді системи контролю версій, де зберігається весь код та конфігурація. Другий принцип вимагає автоматизації збірки, щоб будь-хто міг отримати працюючу версію системи однією командою. Третій принцип наголошує на створенні самотестувальної збірки, де тести є невід'ємною частиною процесу. Четвертий принцип рекомендує кожному розробнику щодня комітити зміни до основної гілки. П'ятий принцип вимагає, щоб кожен коміт запускав збірку на інтеграційній машині. Шостий принцип наголошує на необхідності швидкого виправлення зламаних збірок. Сьомий принцип вимагає, щоб тести виконувались у середовищі, максимально наближеному до продакшн. Восьмий принцип передбачає легкий доступ до останньої збірки для всіх учасників команди.

## Анатомія CI конвеєра

Сучасний CI конвеєр складається з послідовності етапів, кожен з яких виконує специфічну функцію у процесі перевірки та підготовки коду. Розуміння структури конвеєра допомагає проєктувати ефективні та надійні процеси автоматизації.

Типовий конвеєр починається з етапу перевірки коду. На цьому етапі виконується статичний аналіз коду, лінтинг та перевірка форматування. Інструменти статичного аналізу шукають потенційні проблеми без виконання коду, виявляючи типові помилки, вразливості безпеки, порушення стилю кодування. Лінтери перевіряють дотримання правил оформлення коду, що особливо важливо для підтримки консистентності у великих командах.

Наступний етап присвячений збірці застосунку. Для компільованих мов це включає компіляцію вихідного коду у виконувані файли або бібліотеки. Для інтерпретованих мов цей етап може включати перевірку синтаксису, мінімізацію ресурсів, генерацію документації. Важливим аспектом збірки є управління залежностями, яке гарантує, що всі необхідні бібліотеки та пакети доступні у правильних версіях.

Етап тестування є критично важливим для забезпечення якості коду. Конвеєр виконує різні типи тестів у певній послідовності. Спочатку запускаються модульні тести, які перевіряють окремі компоненти у ізоляції. Вони виконуються швидко і надають негайний зворотний зв'язок розробникам. Далі виконуються інтеграційні тести, що перевіряють взаємодію між компонентами. Деякі конвеєри також включають функціональні тести, які перевіряють систему з точки зору користувача.

Етап аналізу якості використовує спеціалізовані інструменти для оцінки різних аспектів коду. Вимірюється покриття коду тестами, аналізується складність коду, виявляються дублікати коду, перевіряється дотримання стандартів безпеки. Результати зазвичай візуалізуються у вигляді звітів та дашбордів, що дозволяє відстежувати тренди якості з часом.

Етап створення артефактів передбачає упакування результатів збірки у формат, придатний для розгортання. Для вебдодатків це можуть бути Docker образи, для бібліотек - JAR файли або npm пакети, для мобільних застосунків - APK або IPA файли. Артефакти зазвичай зберігаються у спеціалізованих репозиторіях з версіонуванням та метаданими.

Фінальний етап може включати автоматичне розгортання у тестове середовище, запуск додаткових тестів продуктивності або безпеки, нотифікацію команди про результати збірки.

```mermaid
graph LR
    A[Коміт коду] --> B[Перевірка коду]
    B --> C[Збірка]
    C --> D[Модульні тести]
    D --> E[Інтеграційні тести]
    E --> F[Аналіз якості]
    F --> G[Створення артефактів]
    G --> H[Розгортання у тестове середовище]
    H --> I[Нотифікація команди]
```

## GitHub Actions: архітектура та можливості

GitHub Actions представляє собою платформу для автоматизації робочих процесів, тісно інтегровану з GitHub репозиторіями. Ця платформа дозволяє описувати складні процеси автоматизації у вигляді YAML файлів, що зберігаються безпосередньо у репозиторії.

Основною одиницею роботи у GitHub Actions є workflow, який описує повний процес автоматизації. Workflow складається з одного або кількох jobs, які можуть виконуватись паралельно або послідовно. Кожен job виконується на окремому runner - віртуальній або фізичній машині. Job містить послідовність steps, кожен з яких виконує конкретну дію.

Workflow визначається у YAML файлі, що розміщується у директорії `.github/workflows` репозиторію. Кожен workflow має ім'я та набір тригерів, які визначають, коли він повинен запускатись. GitHub Actions підтримує різноманітні події як тригери, включаючи push коміту, створення pull request, публікацію релізу, розклад cron, ручний запуск, вебхуки від зовнішніх систем.

Розглянемо детально приклад workflow для вебдодатку на Node.js, який демонструє типові практики організації CI конвеєра.

```yaml
name: Node.js CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [18.x, 20.x, 22.x]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run linter
        run: npm run lint

      - name: Run tests
        run: npm test

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info

  build:
    needs: test
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-files
          path: dist/
```

Цей workflow демонструє кілька важливих концепцій. По-перше, використання матричної стратегії дозволяє тестувати код на різних версіях Node.js паралельно, що забезпечує сумісність з різними середовищами виконання. По-друге, job build залежить від успішного завершення job test через директиву needs, що створює послідовність виконання. По-третє, використання actions/checkout для клонування коду та actions/setup-node для налаштування середовища демонструє концепцію переусувних дій.

GitHub Actions надає потужну систему контексту та виразів, що дозволяє створювати динамічні workflow. Контекст github містить інформацію про поточний репозиторій, коміт, pull request. Контекст env надає доступ до змінних середовища. Контекст secrets дозволяє безпечно використовувати чутливі дані. Вирази у фігурних дужках ${{ }} дозволяють використовувати умовну логіку, обчислення, доступ до контексту.

Важливою особливістю GitHub Actions є екосистема переусувних дій, що доступні через GitHub Marketplace. Це дозволяє використовувати готові рішення для типових завдань, такі як розгортання у хмарні платформи, сканування безпеки, публікація артефактів, надсилання нотифікацій.

## GitLab CI/CD: інтегрована платформа

GitLab CI/CD є вбудованою частиною платформи GitLab, що забезпечує тісну інтеграцію між контролем версій та процесами автоматизації. На відміну від GitHub Actions, GitLab CI/CD використовує концепцію pipeline, яка візуально відображається як граф залежностей між jobs.

Конфігурація GitLab CI/CD описується у файлі `.gitlab-ci.yml` у корені репозиторію. Ключовими концепціями є pipeline, stages та jobs. Pipeline є контейнером верхнього рівня для всіх jobs. Stages визначають логічні етапи pipeline, які виконуються послідовно. Jobs описують конкретні завдання, що виконуються в рамках певного stage.

Розглянемо приклад конфігурації для Python додатку, що демонструє можливості GitLab CI/CD.

```yaml
stages:
  - test
  - build
  - deploy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

cache:
  paths:
    - .cache/pip
    - venv/

.python-setup:
  image: python:3.11
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip install -r requirements.txt

test:lint:
  extends: .python-setup
  stage: test
  script:
    - pip install flake8 black mypy
    - flake8 src/
    - black --check src/
    - mypy src/

test:unit:
  extends: .python-setup
  stage: test
  script:
    - pip install pytest pytest-cov
    - pytest --cov=src tests/
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

build:docker:
  stage: build
  image: docker:24
  services:
    - docker:24-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA .
    - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA $CI_REGISTRY_IMAGE:latest
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest
  only:
    - main

deploy:staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - curl -X POST $WEBHOOK_URL -H "Content-Type: application/json" -d "{\"tag\":\"$CI_COMMIT_SHORT_SHA\"}"
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - main
```

Ця конфігурація демонструє кілька потужних можливостей GitLab CI/CD. Використання шаблону `.python-setup` через директиву extends дозволяє уникнути дублювання коду для налаштування Python середовища. Визначення кешу на рівні pipeline прискорює виконання jobs за рахунок збереження залежностей між запусками. Використання сервісів, зокрема docker:dind для Docker-in-Docker, дозволяє будувати образи всередині контейнера. Директива only обмежує виконання певних jobs тільки для гілки main.

GitLab CI/CD надає вбудовану підтримку для роботи з артефактами. Jobs можуть створювати артефакти, які автоматично зберігаються та доступні для завантаження або використання у наступних jobs. Це особливо корисно для передачі результатів збірки між етапами pipeline.

Система змінних у GitLab CI/CD є дуже гнучкою. Змінні можуть визначатись на різних рівнях - глобально для всього GitLab інстансу, на рівні групи проєктів, на рівні окремого проєкту, у файлі конфігурації. Предефіновані змінні, такі як CI_COMMIT_SHORT_SHA, CI_REGISTRY_IMAGE, надають доступ до інформації про поточний контекст виконання.

GitLab пропонує інтегровану систему для управління середовищами розгортання. Кожен deploy job може бути асоційований з певним середовищем через директиву environment. Це дозволяє відстежувати історію розгортань, порівнювати версії у різних середовищах, легко виконувати відкати до попередніх версій.

## Jenkins: гнучкість та розширюваність

Jenkins є одним з найстаріших та найпопулярніших інструментів для безперервної інтеграції. На відміну від хмарних рішень GitHub Actions та GitLab CI/CD, Jenkins зазвичай встановлюється та управляється самостійно, що надає повний контроль над інфраструктурою але вимагає більше зусиль для підтримки.

Основною перевагою Jenkins є його надзвичайна гнучкість та величезна екосистема плагінів. Існує понад 1800 плагінів, що покривають інтеграцію практично з будь-якими інструментами та платформами. Jenkins підтримує два підходи до визначення pipeline - через веб-інтерфейс з використанням плагіна Pipeline або через код у вигляді Jenkinsfile.

Jenkinsfile використовує доменно-специфічну мову на базі Groovy для опису pipeline. Існує два синтаксиси - декларативний та скриптовий. Декларативний синтаксис є більш структурованим та рекомендованим для більшості випадків, тоді як скриптовий надає більшу гнучкість за рахунок прямого використання Groovy.

Приклад декларативного Jenkinsfile для Java застосунку:

```groovy
pipeline {
    agent {
        docker {
            image 'maven:3.9-eclipse-temurin-17'
            args '-v $HOME/.m2:/root/.m2'
        }
    }

    environment {
        SONAR_TOKEN = credentials('sonar-token')
        DOCKER_REGISTRY = 'registry.example.com'
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }

        stage('Build') {
            steps {
                sh 'mvn clean compile'
            }
        }

        stage('Test') {
            parallel {
                stage('Unit Tests') {
                    steps {
                        sh 'mvn test'
                    }
                    post {
                        always {
                            junit 'target/surefire-reports/*.xml'
                        }
                    }
                }

                stage('Integration Tests') {
                    steps {
                        sh 'mvn verify -DskipUnitTests'
                    }
                }
            }
        }

        stage('Code Quality') {
            steps {
                sh '''
                    mvn sonar:sonar \
                        -Dsonar.host.url=https://sonar.example.com \
                        -Dsonar.token=$SONAR_TOKEN
                '''
            }
        }

        stage('Package') {
            steps {
                sh 'mvn package -DskipTests'
                archiveArtifacts artifacts: 'target/*.jar', fingerprint: true
            }
        }

        stage('Docker Build') {
            when {
                branch 'main'
            }
            steps {
                script {
                    def imageTag = "${DOCKER_REGISTRY}/myapp:${env.BUILD_NUMBER}"
                    docker.build(imageTag)
                    docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                        docker.image(imageTag).push()
                        docker.image(imageTag).push('latest')
                    }
                }
            }
        }
    }

    post {
        success {
            slackSend channel: '#builds', color: 'good', message: "Build ${env.BUILD_NUMBER} succeeded"
        }
        failure {
            slackSend channel: '#builds', color: 'danger', message: "Build ${env.BUILD_NUMBER} failed"
        }
        always {
            cleanWs()
        }
    }
}
```

Цей приклад демонструє кілька важливих концепцій Jenkins. Блок agent визначає, де буде виконуватись pipeline - у даному випадку всередині Docker контейнера з Maven. Блок environment дозволяє визначити змінні середовища, включаючи безпечне отримання credentials через функцію credentials(). Директива parallel дозволяє виконувати кілька stages одночасно для прискорення pipeline. Блок when надає умовну логіку для виконання певних stages. Блок post визначає дії, що виконуються після завершення pipeline залежно від результату.

Jenkins надає потужну систему управління credentials, що дозволяє безпечно зберігати паролі, API ключі, SSH ключі, сертифікати. Credentials можуть бути визначені глобально або на рівні окремих проєктів і використовуються у pipeline через функції withCredentials() або credentials().

Архітектура Jenkins базується на моделі master-agent, де master керує розподілом завдань, а agents виконують фактичну роботу. Це дозволяє масштабувати систему горизонтально, додаючи нові agents для обробки навантаження. Agents можуть бути налаштовані з різними операційними системами та інструментами, що дозволяє підтримувати різноманітні середовища збірки.

## Порівняння платформ та вибір інструменту

Кожна CI платформа має свої сильні та слабкі сторони, і вибір залежить від конкретних потреб команди та проєкту.

GitHub Actions є оптимальним вибором для проєктів, що вже використовують GitHub. Тісна інтеграція з репозиторієм, відсутність необхідності налаштовувати додаткову інфраструктуру, велика екосистема готових дій роблять його привабливим для команд, що хочуть швидко почати з CI/CD. Обмеженням є прив'язка до екосистеми GitHub та ліміти на безкоштовне використання у приватних репозиторіях.

GitLab CI/CD пропонує найбільш інтегрований досвід, об'єднуючи контроль версій, CI/CD, управління проєктами, реєстр контейнерів у єдиній платформі. Це особливо зручно для організацій, що прагнуть мінімізувати кількість інструментів. GitLab може розгортатись як хмарне рішення або самостійно, що надає гнучкість у виборі моделі розгортання.

Jenkins залишається популярним у великих організаціях завдяки своїй гнучкості та можливості повного контролю. Величезна екосистема плагінів дозволяє інтегруватись практично з будь-якими системами. Недоліками є необхідність управління інфраструктурою, складність налаштування та підтримки, застаріла архітектура деяких компонентів.

При виборі платформи варто враховувати наступні фактори. Якщо команда вже використовує певну систему контролю версій, має сенс розглянути нативне CI/CD рішення для неї. Розмір команди та кількість проєктів впливають на вибір між керованим рішенням та самостійним розгортанням. Специфічні вимоги до інтеграції з іншими системами можуть схилити вибір до Jenkins з його екосистемою плагінів. Бюджетні обмеження та доступність ресурсів для підтримки інфраструктури також є важливими факторами.

## Оптимізація продуктивності CI конвеєрів

Продуктивність CI конвеєра напряму впливає на швидкість розробки та задоволеність команди. Повільні конвеєри призводять до затримок у отриманні зворотного зв'язку, що порушуєflow розробників та знижує ефективність безперервної інтеграції.

Одним з ключових підходів до оптимізації є кешування залежностей. Завантаження залежностей з інтернету часто є найповільнішою частиною збірки. Використання кешу для зберігання залежностей між запусками може суттєво скоротити час виконання. GitHub Actions надає вбудовану підтримку кешування через actions/cache. GitLab CI/CD використовує директиву cache. Jenkins пропонує різні плагіни для кешування.

Паралелізація є потужним інструментом для скорочення загального часу виконання конвеєра. Jobs, що не залежать один від одного, можуть виконуватись одночасно. Тести можуть бути розділені на групи та виконуватись паралельно на різних агентах. Матричні стратегії дозволяють тестувати на різних версіях платформ одночасно.

Використання попередньо створених образів може значно прискорити налаштування середовища виконання. Замість встановлення всіх залежностей на кожному запуску, можна створити Docker образ з попередньо встановленими інструментами та використовувати його як базу для виконання jobs.

Інкрементальні збірки дозволяють перекомпілювати тільки змінені частини коду замість повної перезбірки. Це особливо ефективно для великих проєктів з довгим часом компіляції.

Розумний вибір тестів для виконання може суттєво скоротити час конвеєра без втрати якості. Для pull requests можна виконувати тільки тести, що стосуються змінених файлів. Повний набір тестів може виконуватись тільки для гілки main або за розкладом.

## Моніторинг та аналіз CI метрик

Систематичний моніторинг та аналіз метрик CI допомагає виявляти проблеми та можливості для покращення. Ключові метрики включають час виконання конвеєра, частоту провалів збірки, час до виявлення проблеми, покриття коду тестами.

Час виконання конвеєра показує, наскільки швидко розробники отримують зворотний зв'язок. Ідеально, щоб базовий конвеєр виконувався за 10 хвилин або менше. Довші конвеєри призводять до втрати контексту та зниження продуктивності.

Частота провалів збірки є індикатором стабільності процесу розробки. Висока частота провалів може вказувати на проблеми з якістю коду, недостатнім тестуванням або нестабільними тестами.

Час від коміту до виявлення проблеми є критичною метрикою для ефективності CI. Чим швидше виявлена проблема, тим легше її виправити.

Покриття коду тестами показує, наскільки добре код захищений автоматизованими тестами. Хоча висока метрика покриття не гарантує якості тестів, низька метрика чітко вказує на недостатнє тестування.

## Висновки

Побудова ефективних CI конвеєрів вимагає розуміння принципів безперервної інтеграції, особливостей різних платформ та найкращих практик оптимізації. Вибір відповідної платформи залежить від специфічних потреб команди, існуючої інфраструктури та ресурсів.

Успішна імплементація CI вимагає не тільки технічного налаштування інструментів, але й культурних змін у команді. Розробники повинні приймати практику часто комітити код, швидко реагувати на провали збірки, підтримувати високу якість автоматизованих тестів.

Систематична оптимізація та моніторинг CI конвеєрів допомагає підтримувати високу продуктивність та ефективність процесу розробки. Інвестиції у якісну автоматизацію повертаються у вигляді швидшого виявлення проблем, скорочення часу на ручні процеси, підвищення якості програмного забезпечення.

---
